# Асинхронный парсер PEP документации Python
Парсер предназначен для сбора информации о PEP документах Python и количестве статусов документов PEP.

### Используемые технологии:
+ Python 3.7
+ Scrapy
+ Работа с файлами в формате: csv

### Как запустить проект:

Клонировать репозиторий и перейти в него в командной строке:
```
git clone https://github.com/AngelNad/scrapy_parser_pep.git
```
```
cd scrapy_parser_pep/
```

Cоздать и активировать виртуальное окружение:

```
python3 -m venv venv
```
```
source env/bin/activate
```

Установить зависимости из файла requirements.txt:

```
python3 -m pip install --upgrade pip
```
```
pip install -r requirements.txt
```

### Как пользоваться парсером:
Парсер выводит собранную информацию в два файла .csv:
+ В первый файл список всех PEP: номер, название и статус.
+ Второй файл содержит сводку по статусам PEP — сколько найдено документов в каждом статусе (статус, количество).

Чтобы запустить парсер необходимо выполнить команду:
```
scrapy crawl pep
```

Команда спарсит документацию PEP, посчитает количество PEP в каждом статусе, их общую сумму и сохранит результат сбора информации в папку results.